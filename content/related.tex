\chapter{Related work (State-of-the-art)}
In this chapter we would like to introduce some related works,which propose different approaches to the problem of detection and classification of intracranial hemorrhage in non-contrast CT scans.

\section{Identification of intracranial hemorrhage with clinical workflow integration}
In their work \cite{relatedWork1}, Arbabshirani et al. developed a machine learning algorithm, which automatically analyzed head CT scans, flagging those with the presence of a hemorrhage, and thus prioritized radiology work lists in real time. As a result, it became possible to significantly reduce the average time, in which a patient received their diagnosis.  
\subsection*{Methods} 
The machine learning algorithm implemented in this study was a three-dimensional convolutional neural network, with the architecture of five convolutional layers and two fully connected layers. The dataset used in development of the solution contained 46 583 non-contrast head CT studies, each having 20 axial two-dimensional slices. Each study had been manually labeled with a binary value, signalizing the presence of a hemorrhage. These labels were later used as ground truths during training phase. Prior to the network training, the data had been preprocessed with several techniques, such as standardizing the number of axial slices and resizing each slice, so to achieve a uniform dimensions of 256x256x24 for each study, as well as applying windowing, in order to increase the contrast in each of the slices. Thenceforth, the neural network was trained using stochastic gradient descent, until the received loss was near zero. After the training period, the algorithm was tested on previously unseen test data.
\begin{figure}[!ht]
\begin{centering}
\includegraphics[width=16cm]{assets/images/RW1-net-arch.png}
\par\end{centering}
\caption{Model architecture from \footfullcite{relatedWork1} \label{fig:rw1}}
\end{figure}
\subsection*{Clinical implementation} 
Over a three-month period, the trained model had been implemented at a clinic in Pennsylvania, USA to assist with prioritization of radiology work lists. During this implementation phase, 347 head CT studies were processed in real time. For each study, which was fed to the algorithm, a binary output was produced, representing positive or negative presence of ICH. Studies marked as positive were assigned higher priority and moved up the radiology work list. Out of these 94 studies, 60 were determined by a interpreting radiologist as true positive, which gave the model positive predictive value of 64\%. were consequently. With this approach, average diagnostic time was shortened from 8,5 hours to just 19 minutes, which is acceleration of 96\%. The algorithm showed accuracy of 84\% sensitivity of 70\%  and specificity of 87\%. The area under the curve of the model, was established to be 0.846.


\section{Diagnosis of intracranial hemorrhage and subtypes using a three-dimensional joint convolutional and recurrent neural network}

The work of Ye et al. \cite{relatedWork2} resides in combining three-dimensional joint convolutional neural network (CNN) and recurrent neural network (RNN) for the task of detecting intracranial hemorrhage, as well as its five subtypes. The authors conducted a comparison and evaluation of their solution on both slice-level and subject-level (whole 3D CT scan) approaches.

\subsection*{Data and preprocessing}
Dataset containing 2836 non-contrast head CT scans was used, out of which 1836 scans were with positive appearance of intracranial hemorrhage. The remaining 1000 scans had been labeled as healthy, without any hemorrhage. All of the scans were labeled on both, slice - and subject - levels. Typically, data preprocessing forewent the training process. This included resampling and downsampling the original dimensions of the scans. Just like in the previously mentioned study \cite{relatedWork1}, different types of windowing were applied on slice-level. Peprocessed data were then used in two stage training. 
\subsection*{Methods}
During the first stage, a two-type classification was conducted, which predicted the very presence of a bleeding. With this step, every subject not containing intracranial hemorrhage was filtered out, and only the subjects with bleeding occuring were forwarded to the second stage. In this stage, five-type classification determined the subtype of the hemorrhage present in the scan. The convolutional neural network was trained to serve as a feature extractor on a slice level. Followed by a reccurent neural network, which was implemented to "capture sequential information of features from consecutive slices, adding inter-slice dependency context to boost classification performance" \cite{relatedWork2}. To introduce some explainability and review the regions upon which their model made predictions, authors used the Grad-CAM method, which generated heatmaps based on most relevant regions of input images.
\begin{figure}[!ht]
\begin{centering}
\includegraphics[width=15cm]{assets/images/RW2.jpg}
\par\end{centering}
\caption{Heatmpas generated with the Grad-CAM \footfullcite{relatedWork2} \label{fig:rw2}}
\end{figure}
\\
\\
\\
\section{Intracranial hemorrhage detection and classification with Convolutional and Long Short-term Memory neural networks}
We chose to introduce the work of Burduja et. al \cite{relatedWork3} since the authors worked with the same dataset as we do in our work, which is the RSNA ICH detection challenge 2019 dataset \cite{RSNAchallenge}. The approach presented in this work is based on a combination of Convoltional neural network with a bi-directional Long Short-term Memory network for detection and subtype classification of ICH from 3D CT scans.
\subsection*{Data and preprocessing}
The dataset used in this publication contained 25 272 CT scans with a total of 870 301 CT slices \cite{RSNAchallenge}. Each slice is annotated considering the presence or absence of ICH as well as the subtype. Slices can be associated by their series ID to form a 3D CT scan. During the preprocessing stage, windowing on slice level was applied, namely brain, subdural and soft tissue window, followed by combining these slice modifications to a single three-channel image. Furthermore, reduction of spatial dimensions and normalization of pixel values was conducted.
\subsection*{Methods}
To solve the objective task \cite{relatedWork3}, the authors present a system based on two different types of deep neural networks. First, using the popular transfer learning approach, a Convolutional neural network with ResNeXt-101 architecture is implemented, to make subtype predictions at the CT-slice level. This network had been pretrained on 940 million natural images. The main novelty introduced in this work is using a feature extraction technique. The second-to-last layer of the CNN outputs a 2048-dimensional feature vector, which poses the risk of high computational requirements. Two different feature extraction methods are used in order to reduce computational time of the model. First one considers the weights assigned by softmax layer to each feature. Alternatively, second method is the so called Principal component analysis (PCA), which is described as "a dimensionality reduction method that projects the data points in a new subspace, in which the features (components) are orthogonal and in decreasing order of variance" \cite{relatedWork3}. The reduced feature vector is then fed to a bi-directional Long Short-term Memory (LSTM) network, a special type of recurrent neural network, which relies on a sequence input data. It is a suitable approach for whole CT examinations, as CT-scan slices have a natural order. When considering the neighbouring slices, spurious findings in a single slice can be detected and corrected. This way, the network is able to take into account the whole 3D context of CT scans and improve overall accuracy.
\subsection*{Results}
The presented model was able to provide favorable results \cite{relatedWork3}. According to measured metrics, the model performed overall better at slice-level than at scan-level. Accuracy score at the slice level was for all ICH subtypes typically above 96.00\%. It was observed, that introducing the bidirectional LSTM resulted in significant improvement of specificity scores, outreaching 99\% in many cases. The model's performance was also compared to three trained radiologists. This study revealed, that the model attains scores very close to those of two of the three radiologists, sometimes even surpasses them. It was therefore concluded, that the deep learning system could be used in practice as a second opinion to trained radiologists.
% \begin{figure}[!ht]
% \begin{centering}
% \includegraphics[width=15cm]{assets/images/RW3.jpg}
% \par\end{centering}
% \caption{Model architecture from \footfullcite{relatedWork3} \label{fig:rw3}}
% \end{figure}